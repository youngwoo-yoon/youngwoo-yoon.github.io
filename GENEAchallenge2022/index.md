# The GENEA Challenge 2022: A large evaluation of data-driven co-speech gesture generation

Youngwoo Yoon*, Pieter Wolfert*, Taras Kucherenko*, Carla Viegas, Teodor Nikolov, Mihail Tsakov, Gustav Eje Henter

## Summary

We reports on the second GENEA Challenge to benchmark data-driven automatic co-speech gesture generation. Participating teams used a common speech and motion dataset to build gesture-generation systems. Motion generated by all these systems was rendered to video using a standardised visualisation pipeline and evaluated in several large, crowdsourced user studies. This year's dataset was based on 18 hours of full-body motion capture, including fingers, of different persons engaging in dyadic conversation. 10 teams participated in the evaluation across two tiers: full-body and upper-body gesticulation. For each tier we evaluated both the human-likeness of the gesture motion and its appropriateness for the specific speech. The evaluation results are a revolution, and a revelation. Some synthetic conditions are rated as significantly more human-like than human motion capture. On the other hand, all synthetic motion is found to be vastly less appropriate for the speech than the original motion-capture recordings.

In this webpage, we share all related resources including data, codes, and results. Please see our paper (link will be available soon) for more information.


## Open-source materials

* Data
  * Challenge dataset: To be updated
  * User-study video stimuli: To be updated
  * Submitted BVH files: To be updated
* Code
  * Visualization code: [github.com/TeoNikolov/genea_visualizer](https://github.com/TeoNikolov/genea_visualizer)
  * Numerical evaluation code: [github.com/genea-workshop/genea_numerical_evaluations](https://github.com/genea-workshop/genea_numerical_evaluations)
  * Baselines: [Text-based baseline (Yoon et al., ICRA 2019)](https://github.com/youngwoo-yoon/Co-Speech_Gesture_Generation), [Audio-based baseline (Kucherenko et al., IVA 2019)](https://github.com/genea-workshop/Speech_driven_gesture_generation_with_autoencoder/tree/GENEA_2022)
* Results
  * Subjective evaluation data: [DOI/10.5281/zenodo.6940057](https://doi.org/10.5281/zenodo.6940057)
* Papers
  * To be updated

## Citation
```
@inproceedings{yoon2022genea,
  author={Yoon, Youngwoo and Wolfert, Pieter and Kucherenko, Taras and Viegas, Carla and Nikolov, Teodor and Tsakov, Mihail and Henter, Gustav Eje},
  title={{T}he {GENEA} {C}hallenge 2022: {A} large evaluation of data-driven co-speech gesture generation},
  booktitle={Proceedings of the ACM International Conference on Multimodal Interaction},
  publisher={ACM},
  series={ICMI '22},
  year={2022}
}
```


